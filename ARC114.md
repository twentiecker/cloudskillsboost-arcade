# Analyze Speech & Language with Google APIs: Challenge Lab

## Task 1. Create an API key

#### 1. For this task, you need to create an API key to use in this and other tasks when sending a request to the Natural Language API.

#### 2. Save the API key to use in other tasks.

---

## Task 2. Make an entity analysis request and call the Natural Language API

#### 1. For this task, connect to the instance <INSTANCE_NAME> provisioned for you via SSH.

#### 2. Next, create a JSON file named nl_request.json which you will pass to the Natural Language API for analysis. You can add the provided lab code to your JSON file to analyze text about the city of Boston or, alternatively, add text of your own choosing to the content object to perform entity analysis on that instead.

```bash
nano nl_request.json
```

#### 3. You can now pass your request body, along with the API key environment variable you saved earlier, to the Natural Language API using the curl command or analyze the text using gcloud ML commands.

```bash
export API_KEY=<API_KEY>
```

```bash
curl "https://language.googleapis.com/v1/documents:analyzeEntities?key=${API_KEY}" \
  -s -X POST -H "Content-Type: application/json" --data-binary @nl_request.json > nl_response.json
```

#### 4. Save the response in a file called nl_response.json.

---

## Task 3. Create a speech analysis request and call the Speech API

#### 1. Create another JSON file, named speech_request.json for this task, and add the content using the URI value of the provided sample audio file.

```bash
nano speech_request.json
```

#### 2. You can now pass your request body, along with the API key environment variable that you saved earlier, to the Natural Language API using the curl command or analyze the speech using gcloud ML commands.

```bash
curl -s -X POST -H "Content-Type: application/json" --data-binary @speech_request.json \
  "https://speech.googleapis.com/v1/speech:recognize?key=${API_KEY}" > speech_response.json
```

#### 3. Save the response in a file named speech_response.json.

---

## Task 4. Analyze sentiment with the Natural Language API

#### For this task, you need to analyze text sentiment using the Google Cloud Natural Language API, which attempts to determine the overall attitude (positive or negative) of a content sample such as a movie review. In the <INSTANCE_NAME> instance, a simple Python application code file called sentiment_analysis.py has already been configured and created for you. To perform your analysis, you'll test it on a set of (fictitious or fake) movie reviews for the 1982 sci-fi action film, Blade Runner, directed by Ridley Scott.

#### To use the Natural Language API to perform sentiment analysis, you need to access the service by calling the analyze_sentiment method of the LanguageServiceClient instance.

#### 1. You need to edit the method def analyze(movie_review_filename): in the file sentiment_analysis.py and complete the method using Python code that performs the following actions:

```bash
nano sentiment_analysis.py
```

> Instantiate a LanguageServiceClient instance as the client.

```bash
# Instantiate a LanguageServiceClient instance as the client.
client = language_v1.LanguageServiceClient()
```

> Read the filename containing the text data into a variable.

```bash
# Read the filename containing the text data into a variable.
with open(movie_review_filename) as review_file:
    content = review_file.read()
```

> Instantiate a Document object with the contents of the file.

```bash
# Instantiate a Document object with the contents of the file.
document = language_v1.Document(
    content=content, type_=language_v1.Document.Type.PLAIN_TEXT
)
```

> Call the client's analyze_sentiment method.

```bash
# Call the client's analyze_sentiment method.
annotations = client.analyze_sentiment(request={"document": document})

# Print the results
print_result(annotations)
```

#### 2. Download the fictitious movie review samples from Google Cloud Storage: gs://cloud-samples-tests/natural-language/sentiment-samples.tgz .

```bash
gsutil cp gs://cloud-samples-tests/natural-language/sentiment-samples.tgz .
```

#### 3. Unzip the sample files and run the sentiment analysis on one of the files, bladerunner-pos.txt, using the relevant Python command.

```bash
gunzip sentiment-samples.tgz
```

```bash
tar -xvf sentiment-samples.tar
```

```bash
python3 sentiment_analysis.py reviews/bladerunner-pos.txt
```
