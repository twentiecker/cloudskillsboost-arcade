# Cloud Run Functions: 3 Ways: Challenge Lab

## Task 1. Create a Cloud Storage bucket

#### Create a Cloud Storage bucket in Region using your Project ID as the bucket name: <BUCKET_NAME>

```bash
export REGION=<REGION>
```

```bash
export BUCKET_NAME=<BUCKET_NAME>
```

```bash
gsutil mb -l $REGION gs://$BUCKET_NAME
```

---

## Task 2. Create, deploy, and test a Cloud Storage function

#### Execute the following command to enable all necessary services.

```bash
gcloud services enable \
  artifactregistry.googleapis.com \
  cloudfunctions.googleapis.com \
  cloudbuild.googleapis.com \
  eventarc.googleapis.com \
  run.googleapis.com \
  logging.googleapis.com \
  pubsub.googleapis.com
```

#### To use Cloud Storage functions, first grant the pubsub.publisher IAM role to the Cloud Storage service account

```bash
export PROJECT_ID=$(gcloud config get-value project)
```

```bash
PROJECT_NUMBER=$(gcloud projects list --filter="project_id:$PROJECT_ID" --format='value(project_number)')
```

```bash
SERVICE_ACCOUNT=$(gsutil kms serviceaccount -p $PROJECT_NUMBER)
```

```bash
gcloud projects add-iam-policy-binding $PROJECT_ID \
  --member serviceAccount:$SERVICE_ACCOUNT \
  --role roles/pubsub.publisher
```

#### 1. Create and deploy a Cloud Function called <CLOUD_STORAGE_FUNCTION_NAME> that executes every time a new event occurs in the bucket called <BUCKET_NAME> you created in task 1. The function is written in Node.js 20.

#### 2. Set the Region to <REGION>, and set the Entry point (Function to execute) to your function name.

#### 3. Deploy the function with 2 maximum instances.

#### 4. Use the provided lab code blocks for the index.js and package.json. In index.js file (replace eventStorage with your function name)

```bash
nano index.js
```

```bash
nano package.js
```

```bash
export CLOUD_STORAGE_FUNCTION_NAME=<CLOUD_STORAGE_FUNCTION_NAME>
```

```bash
gcloud functions deploy $CLOUD_STORAGE_FUNCTION_NAME \
  --gen2 \
  --runtime nodejs20 \
  --entry-point $CLOUD_STORAGE_FUNCTION_NAME \
  --source . \
  --region $REGION \
  --trigger-bucket $BUCKET_NAME \
  --trigger-location $REGION \
  --max-instances 2
```

#### 5. Test the function by uploading any file to the bucket.

---

## Task 3. Create and deploy a HTTP function with minimum instances

#### 1. Create and deploy a HTTP function called <HTTP_CLOUD_FUNCTION_NAME> that responds to HTTP requests. The function is written in Node.js 20.

#### 2. Set the Region to <REGION>, and set the Entry point (Function to execute) to your function name.

#### 3. Deploy the function with 1 minimum instance and 2 maximum instances.

#### 4. Use the provided lab code blocks for the index.js and package.json. In index.js file (replace helloWorld with your function name).

```bash
nano index.js
```

```bash
nano package.js
```

```bash
gcloud functions deploy $HTTP_CLOUD_FUNCTION_NAME \
  --gen2 \
  --runtime nodejs20 \
  --entry-point $HTTP_CLOUD_FUNCTION_NAME \
  --source . \
  --region $REGION \
  --trigger-http \
  --timeout 600s \
  --max-instances 2 \
  --min-instances 1
```
